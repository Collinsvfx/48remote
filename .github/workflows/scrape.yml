name: Scrape Remote Jobs

on:
  schedule:
    - cron: "*/20 * * * *" # every 20 minutes
  workflow_dispatch: # allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install --with-deps chromium

      - name: Run Scraper
        run: python scraper.py

      - name: Check for changes
        id: git-check
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add jobs.json || echo "No jobs.json to add"
          if git diff --staged --quiet; then
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and Push if Changed
        if: steps.git-check.outputs.changed == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Fetch and rebase to avoid "fetch first" errors
          git fetch origin main
          git rebase origin/main || true

          git add jobs.json
          git commit -m "Updated jobs.json [auto]" || echo "No changes to commit"
          git push origin HEAD:main --force
